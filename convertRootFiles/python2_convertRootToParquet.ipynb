{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ae13314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.20/06\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa # pip install pyarrow==0.7.1\n",
    "import ROOT\n",
    "import numpy as np\n",
    "import glob, os\n",
    "from skimage.measure import block_reduce # pip install scikit-image\n",
    "from numpy.lib.stride_tricks import as_strided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a314b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_array(x, b0, b1):\n",
    "\n",
    "    r, c = x.shape                                    # number of rows/columns\n",
    "    rs, cs = x.strides                                # row/column strides\n",
    "    x = as_strided(x, (r, b0, c, b1), (rs, 0, cs, 0)) # view as a larger 4D array\n",
    "\n",
    "    return x.reshape(r*b0, c*b1)/(b0*b1)              # create new 2D array with same total occupancy \n",
    "\n",
    "def resample_EE(imgECAL, factor=2):\n",
    "\n",
    "    # EE-\n",
    "    imgEEm = imgECAL[:140-85] # EE- in the first 55 rows\n",
    "    imgEEm = np.pad(imgEEm, ((1,0),(0,0)), 'constant', constant_values=0) # for even downsampling, zero pad 55 -> 56\n",
    "    imgEEm_dn = block_reduce(imgEEm, block_size=(factor, factor), func=np.sum) # downsample by summing over [factor, factor] window\n",
    "    imgEEm_dn_up = upsample_array(imgEEm_dn, factor, factor)/(factor*factor) # upsample will use same values so need to correct scale by factor**2\n",
    "    imgECAL[:140-85] = imgEEm_dn_up[1:] ## replace the old EE- rows\n",
    "\n",
    "    # EE+\n",
    "    imgEEp = imgECAL[140+85:] # EE+ in the last 55 rows\n",
    "    imgEEp = np.pad(imgEEp, ((0,1),(0,0)), 'constant', constant_values=0) # for even downsampling, zero pad 55 -> 56\n",
    "    imgEEp_dn = block_reduce(imgEEp, block_size=(factor, factor), func=np.sum) # downsample by summing over [factor, factor] window\n",
    "    imgEEp_dn_up = upsample_array(imgEEp_dn, factor, factor)/(factor*factor) # upsample will use same values so need to correct scale by factor*factor\n",
    "    imgECAL[140+85:] = imgEEp_dn_up[:-1] # replace the old EE+ rows\n",
    "\n",
    "    return imgECAL\n",
    "\n",
    "def crop_jet(imgECAL, iphi, ieta, jet_shape=125):\n",
    "\n",
    "    # NOTE: jet_shape here should correspond to the one used in RHAnalyzer\n",
    "    off = jet_shape//2\n",
    "    iphi = int(iphi*5 + 2) # 5 EB xtals per HB tower\n",
    "    ieta = int(ieta*5 + 2) # 5 EB xtals per HB tower\n",
    "\n",
    "    # Wrap-around on left side\n",
    "    if iphi < off:\n",
    "        diff = off-iphi\n",
    "        img_crop = np.concatenate((imgECAL[:,ieta-off:ieta+off+1,-diff:],\n",
    "                                   imgECAL[:,ieta-off:ieta+off+1,:iphi+off+1]), axis=-1)\n",
    "    # Wrap-around on right side\n",
    "    elif 360-iphi < off:\n",
    "        diff = off - (360-iphi)\n",
    "        img_crop = np.concatenate((imgECAL[:,ieta-off:ieta+off+1,iphi-off:],\n",
    "                                   imgECAL[:,ieta-off:ieta+off+1,:diff+1]), axis=-1)\n",
    "    # Nominal case\n",
    "    else:\n",
    "        img_crop = imgECAL[:,ieta-off:ieta+off+1,iphi-off:iphi+off+1]\n",
    "\n",
    "    return img_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f71535c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/eos/home-i02/r/rchudasa/SWAN_projects/e2e/MLAnalyzer/convertRootFiles\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "474cc203",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = '/eos/home-i02/r/rchudasa/SWAN_projects/e2e/MLAnalyzer/output_100.root'\n",
    "outdir = '/eos/home-i02/r/rchudasa/SWAN_projects/e2e/MLAnalyzer/'\n",
    "decay = 'DYToTauTau'\n",
    "\n",
    "#infile = '/eos/cms/store/group/phys_heavyions/rchudasa/e2e/'\n",
    "#outdir = '/eos/cms/store/group/phys_heavyions/rchudasa/e2e/RHAnalyzer_Ntuples/DYToTauTau_M-50_13TeV'\n",
    "#decay = 'DYToTauTau_M-50_13TeV'\n",
    "\n",
    "idx = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e70bfde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' >> Input file:', '/eos/home-i02/r/rchudasa/SWAN_projects/e2e/MLAnalyzer/output_100.root')\n",
      "(' >> nEvts:', 1933L)\n",
      "(' >> Output file:', '/eos/home-i02/r/rchudasa/SWAN_projects/e2e/MLAnalyzer//DYToTauTau.parquet.0')\n"
     ]
    }
   ],
   "source": [
    "rhTreeStr = infile \n",
    "rhTree = ROOT.TChain(\"fevt/RHTree\")\n",
    "rhTree.Add(rhTreeStr)\n",
    "nEvts = rhTree.GetEntries()\n",
    "assert nEvts > 0\n",
    "print (\" >> Input file:\",rhTreeStr)\n",
    "print (\" >> nEvts:\",nEvts)\n",
    "outStr = '%s/%s.parquet.%d'%(outdir, decay, idx) \n",
    "print (\" >> Output file:\",outStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f7635f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' >> Processing entries: [', 0, '->', 40, ')')\n",
      "\n",
      "(' .. Processing entry', 0)\n",
      "('event', 0, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 1, ' no of jets', 2)\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 2, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 3, ' no of jets', 2)\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 4, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 5, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 6, ' no of jets', 2)\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 7, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 8, ' no of jets', 2)\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 9, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "(' .. Processing entry', 10)\n",
      "('event', 10, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 11, ' no of jets', 1)\n",
      "[1.0, array([5.58279705])]\n",
      "\n",
      "('event', 12, ' no of jets', 2)\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 13, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 14, ' no of jets', 2)\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 15, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 16, ' no of jets', 2)\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 17, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 18, ' no of jets', 2)\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 19, ' no of jets', 2)\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "(' .. Processing entry', 20)\n",
      "('event', 20, ' no of jets', 2)\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 21, ' no of jets', 2)\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 22, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 23, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 24, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 25, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 26, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 27, ' no of jets', 2)\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "('2 Sec vertex pt:', 1)\n",
      "[1.0, array([14.98342609])]\n",
      "\n",
      "('event', 28, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 29, ' no of jets', 1)\n",
      "[1.0, array([18.71267319])]\n",
      "\n",
      "(' .. Processing entry', 30)\n",
      "('event', 30, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 31, ' no of jets', 1)\n",
      "[1.0, array([28.10563278])]\n",
      "\n",
      "('event', 32, ' no of jets', 1)\n",
      "[1.0, array([14.05618477])]\n",
      "\n",
      "('event', 33, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 34, ' no of jets', 2)\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 35, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 36, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 37, ' no of jets', 1)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 38, ' no of jets', 2)\n",
      "('2 Sec vertex pt:', 1)\n",
      "[1.0, array([10.12679672])]\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "\n",
      "('event', 39, ' no of jets', 2)\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "('2 Sec vertex pt:', 0)\n",
      "[1.0, array([0.])]\n",
      "(' >> nJets:', 55)\n",
      "(' >> Real time:', 0.4157954494158427, 'minutes')\n",
      "(' >> CPU time: ', 0.04700000000000001, 'minutes')\n",
      "========================================================\n"
     ]
    }
   ],
   "source": [
    "# Event range to process\n",
    "iEvtStart = 0\n",
    "iEvtEnd   = 40\n",
    "#iEvtEnd   = nEvts \n",
    "assert iEvtEnd <= nEvts\n",
    "print (\" >> Processing entries: [\",iEvtStart,\"->\",iEvtEnd,\")\")\n",
    "\n",
    "nJets = 0\n",
    "data = {} # Arrays to be written to parquet should be saved to data dict\n",
    "sw = ROOT.TStopwatch()\n",
    "sw.Start()\n",
    "for iEvt in range(iEvtStart,iEvtEnd):\n",
    "    print(\"\")\n",
    "\n",
    "    # Initialize event\n",
    "    rhTree.GetEntry(iEvt)\n",
    "\n",
    "    if iEvt % 10 == 0:\n",
    "        print (\" .. Processing entry\",iEvt)\n",
    "\n",
    "    ECAL_energy = np.array(rhTree.ECAL_energy).reshape(280,360)\n",
    "    ECAL_energy = resample_EE(ECAL_energy)\n",
    "    HBHE_energy = np.array(rhTree.HBHE_energy).reshape(56,72)\n",
    "    HBHE_energy = upsample_array(HBHE_energy, 5, 5) # (280, 360)\n",
    "    TracksAtECAL_pt    = np.array(rhTree.ECAL_tracksPt_atECALfixIP).reshape(280,360)\n",
    "    TracksAtECAL_dZSig = np.array(rhTree.ECAL_tracksDzSig_atECALfixIP).reshape(280,360)\n",
    "    TracksAtECAL_d0Sig = np.array(rhTree.ECAL_tracksD0Sig_atECALfixIP).reshape(280,360)\n",
    "    PixAtEcal_1        = np.array(rhTree.BPIX_layer1_ECAL_atPV).reshape(280,360)\n",
    "    PixAtEcal_2        = np.array(rhTree.BPIX_layer2_ECAL_atPV).reshape(280,360)\n",
    "    PixAtEcal_3        = np.array(rhTree.BPIX_layer3_ECAL_atPV).reshape(280,360)\n",
    "    PixAtEcal_4        = np.array(rhTree.BPIX_layer4_ECAL_atPV).reshape(280,360)\n",
    "    TibAtEcal_1        = np.array(rhTree.TIB_layer1_ECAL_atPV).reshape(280,360)\n",
    "    TibAtEcal_2        = np.array(rhTree.TIB_layer2_ECAL_atPV).reshape(280,360)\n",
    "    TobAtEcal_1        = np.array(rhTree.TOB_layer1_ECAL_atPV).reshape(280,360)\n",
    "    TobAtEcal_2        = np.array(rhTree.TOB_layer2_ECAL_atPV).reshape(280,360)\n",
    "    #X_CMSII            = np.stack([TracksAtECAL_pt, TracksAtECAL_dZSig, TracksAtECAL_d0Sig, ECAL_energy, HBHE_energy], axis=0) # (5, 280, 360)\n",
    "    #X_CMSII            = np.stack([TracksAtECAL_pt, TracksAtECAL_dZSig, TracksAtECAL_d0Sig, ECAL_energy, HBHE_energy, PixAtEcal_1, PixAtEcal_2, PixAtEcal_3, PixAtEcal_4, TibAtEcal_1, TibAtEcal_2, TobAtEcal_1, TobAtEcal_2], axis=0) # (13, 280, 360)\n",
    "    X_CMSII            = np.stack([TracksAtECAL_pt, TracksAtECAL_dZSig, TracksAtECAL_d0Sig, ECAL_energy, \n",
    "                                   HBHE_energy, PixAtEcal_1, PixAtEcal_2, PixAtEcal_3, PixAtEcal_4, \n",
    "                                   TibAtEcal_1, TibAtEcal_2, TobAtEcal_1, TobAtEcal_2], axis=0) # (13, 280, 360)\n",
    "    #X_CMSII            = np.stack([TracksAtECAL_pt, ECAL_energy, HBHE_energy, PixAtEcal_1, \n",
    "    #                               PixAtEcal_2, PixAtEcal_3, PixAtEcal_4], axis=0) #\n",
    "    #data['X_CMSII']    = np.stack([TracksAtECAL_pt, ECAL_energy, HBHE_energy, PixAtEcal_1, \n",
    "    #                               PixAtEcal_2, PixAtEcal_3, PixAtEcal_4], axis=0) # (7, 280, 360)\n",
    "    #data['X_CMSII'] = np.stack([TracksAtECAL_pt, ECAL_energy, HBHE_energy], axis=0) # (3, 280, 360)\n",
    "    #data['X_CMSII'] = np.stack([TracksAtECAL_pt, TracksAtECAL_dz, TracksAtECAL_d0, ECAL_energy], axis=0) # (4, 280, 360)\n",
    "    #data['X_CMSII'] = np.stack([TracksAtECAL_pt, TracksAtECAL_dz, TracksAtECAL_d0, ECAL_energy, HBHE_energy, PixAtEcal_1, PixAtEcal_2, PixAtEcal_3, PixAtEcal_4], axis=0) # (9, 280, 360)\n",
    "\n",
    "    # Jet attributes \n",
    "    ys      = rhTree.jet_IsTau\n",
    "    jetMs   = rhTree.jet_M\n",
    "    jetPts  = rhTree.jet_Pt\n",
    "    dRs    = rhTree.jet_GendR\n",
    "    iphis  = rhTree.jetSeed_iphi\n",
    "    ietas  = rhTree.jetSeed_ieta\n",
    "    pdgIds = rhTree.gen_pdgId\n",
    "    \n",
    "    njets  = len(ys)\n",
    "\n",
    "    print (\"event\", iEvt, \" no of jets\", njets)\n",
    "    #print(\"subjet \", type(np.array(rhTree.subJetE)[0]))\n",
    "    for i in range(njets):\n",
    "\n",
    "        data['y']       = ys[i]\n",
    "        '''\n",
    "        data['jetM']    = jetMs[i]\n",
    "        data['jetPt']   = jetPts[i]\n",
    "        data['dR']    = dRs[i]\n",
    "        data['iphi']  = iphis[i]\n",
    "        data['ieta']  = ietas[i]\n",
    "        data['pdgId'] = pdgIds[i]\n",
    "        data['metSumEt'] = np.float32(rhTree.MET_sumET)[0]\n",
    "        data['nPVtx']    = rhTree.nVtx\n",
    "        data['nPVtx_x']  = np.array(rhTree.Vtx_x)[0]\n",
    "        data['nPVtx_y']  = np.array(rhTree.Vtx_y)[0]\n",
    "        data['X_jet'] = crop_jet(X_CMSII, data['iphi'], data['ieta']) # (13, 125, 125)\n",
    "        #data['X_jet'] = X_CMSII # (13, 125, 125)\n",
    "        '''\n",
    "        #data['sec_vtx_Pt'] = np.array(1, dtype=float)\n",
    "        if njets >1 :\n",
    "            #data['jet_pfcand_E'] = np.array(np.array(rhTree.jetPFCandE)[i], dtype=float)\n",
    "            #data['sec_vtx_Pt'] =  np.array(np.array(rhTree.jetSV_Pt)[i], dtype=float)\n",
    "            print(\"2 Sec vertex pt:\", np.array(np.array(rhTree.jetSV_Pt)[i], dtype=float).size ) \n",
    "            numSecVtx = np.array(np.array(rhTree.jetSV_Pt)[i], dtype=float).size\n",
    "            if numSecVtx == 0:\n",
    "                data['sec_vtx_Pt'] = np.array([0.0])\n",
    "            else:\n",
    "                data['sec_vtx_Pt'] =  np.array(np.array(rhTree.jetSV_Pt)[i], dtype=float)\n",
    "                \n",
    "\n",
    "\n",
    "        else :\n",
    "            #data['jet_pfcand_E'] = np.array(rhTree.jetPFCandE, dtype=float)[i]\n",
    "            numSecVtx = np.array(rhTree.jetSV_Pt, dtype=float)[i].size\n",
    "            if numSecVtx == 0:\n",
    "                data['sec_vtx_Pt'] = np.array([0.0])\n",
    "            else:\n",
    "                data['sec_vtx_Pt'] = np.array(rhTree.jetSV_Pt, dtype=float)[i]\n",
    "            #data['sec_vtx_Pt'] =  np.array(rhTree.jetSV_Pt, dtype=float)[i]\n",
    "            #print(\"Sec vertex pt:\", np.array(rhTree.jetSV_Pt)[i] )\n",
    "            #print(\"1 Sec vertex pt: \", data['sec_vtx_Pt'].size, data['sec_vtx_Pt'])   \n",
    "\n",
    "                  \n",
    "        \n",
    "        #print(\"subjet array size:\", np.array(rhTree.subJetE)[i])\n",
    "\n",
    "        # Create pyarrow.Table\n",
    "        #for d in data.values():\n",
    "        #    print(d)\n",
    "\n",
    "        pqdata = [pa.array([d]) if (np.isscalar(d) or type(d) == list) else pa.array([d.tolist()]) for d in data.values()]\n",
    "\n",
    "        print(data.values())\n",
    "        table = pa.Table.from_arrays(pqdata, list(data.keys()))\n",
    "\n",
    "        if nJets == 0:\n",
    "            writer = pq.ParquetWriter(outStr, table.schema, compression='snappy')\n",
    "\n",
    "        writer.write_table(table)\n",
    "\n",
    "        nJets += 1\n",
    "\n",
    "        #print(\"Event:\", iEvt, \"  jetM:\", jetMs[i], \" pt:\" , jetPts[i], \" iPhi:\", iphis[i], \" iEta:\", ietas[i])\n",
    "\n",
    "writer.close()\n",
    "print (\" >> nJets:\",nJets)\n",
    "print (\" >> Real time:\",sw.RealTime()/60.,\"minutes\")\n",
    "print (\" >> CPU time: \",sw.CpuTime() /60.,\"minutes\")\n",
    "print (\"========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92c4359e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available kernels:\r\n",
      "  ir         /cvmfs/sft.cern.ch/lcg/views/LCG_97a/x86_64-centos7-gcc8-opt/share/jupyter/kernels/ir\r\n",
      "  octave     /cvmfs/sft.cern.ch/lcg/views/LCG_97a/x86_64-centos7-gcc8-opt/share/jupyter/kernels/octave\r\n",
      "  python2    /cvmfs/sft.cern.ch/lcg/views/LCG_97a/x86_64-centos7-gcc8-opt/share/jupyter/kernels/python2\r\n",
      "  root       /cvmfs/sft.cern.ch/lcg/views/LCG_97a/x86_64-centos7-gcc8-opt/etc/notebook/kernels/root\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b12f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
